This is a log of one programmers study and exploration of machine learning technology and what it all means. The goal is to remember what I did and how, instead of insightful observations.

## 2/17/2017
[Tensorflow 1.0](https://research.googleblog.com/2017/02/announcing-tensorflow-10.html) was announced this Tuesday during the 2017 Dev Summit. I've been slowly watching the [released videos](https://www.youtube.com/playlist?list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv). I've been surprised to see how many new capabilities have been added in the past several months, including the ability to compile models to optimized ARM assembly for running on a mobile device using [XLA compiler](https://www.youtube.com/watch?v=kAOanJczHA0), Windows support and a Keras high-level API.

To celebrate the occasion I managed to install version 1.0 on both my Mac Book Pro and an Ubuntu [AWS P2 instance](https://aws.amazon.com/ec2/instance-types/p2/). On macOS I had to upgrade to Cuda SDK 8.0, and then debug why Tensorflow couldn't find the cuda libraries. The solution was to make sure that both `LD_LIBRARY_PATH` and `DYLD_LIBRARY_PATH` environment variables included the cuda library paths (`/usr/local/cuda/lib` in my case). Before this fix `import tensorflow` would cause python to crash without any errors, so I had to learn how to run python in a debugger: `lldb -f python -- test.py`.

The AWS P2 instance was setup using the [setup_p2.sh script](https://github.com/fastai/courses/blob/master/setup/setup_p2.sh) from the [fast.ai course](http://course.fast.ai/lessons/aws.html). This image was setup with [Anaconda Python](https://www.continuum.io/downloads), [Theano](http://deeplearning.net/software/theano/) and [Keras](https://keras.io). The Tensorflow installation was as simple as `pip install tensorflow_gpu`. My test code started running on an Nvidia K80 GPU right away at $0.90/hr. I also have to pay ~$12/month for storing a 128GB disk image.
